import json
from datasets import load_dataset
from tqdm import tqdm

def format_dataset():
    dataset_name = "OpenLLM-Ro/ro_sft_ultrachat"
    output_filename = "ro_ultrachat_formatted.json"

    print(f"ğŸ“¥ Ãncepem streaming-ul pentru: {dataset_name}...")
    
    # MODIFICARE MAJORÄ‚: AdÄƒugÄƒm streaming=True
    # Asta Ã®nseamnÄƒ cÄƒ nu descarcÄƒ totul Ã®n RAM, ci citeÈ™te pe mÄƒsurÄƒ ce proceseazÄƒ.
    try:
        dataset = load_dataset(dataset_name, split="train", streaming=True)
    except Exception as e:
        print(f"Eroare la conexiune/Ã®ncÄƒrcare: {e}")
        return

    formatted_data = []
    
    print("âš™ï¸  Se proceseazÄƒ datele (acest pas poate dura puÈ›in, dar e sigur)...")

    # Fiind streaming, nu È™tim lungimea totalÄƒ exactÄƒ din start, deci tqdm va arÄƒta doar numÄƒrul procesat
    for row in tqdm(dataset):
        original_messages = row.get('messages') or row.get('conversations')
        
        if not original_messages:
            continue

        new_messages = []
        
        for msg in original_messages:
            role = msg.get('role')
            content = msg.get('content')

            if role == 'human':
                role = 'user'
            elif role in ['gpt', 'bot']:
                role = 'assistant'

            new_messages.append({
                "role": role,
                "content": content
            })

        formatted_data.append({
            "messages": new_messages
        })

    print(f"ğŸ’¾ Se salveazÄƒ {len(formatted_data)} conversaÈ›ii Ã®n {output_filename}...")
    
    with open(output_filename, "w", encoding="utf-8") as f:
        json.dump(formatted_data, f, indent=2, ensure_ascii=False)

    print("âœ… Gata! FiÈ™ierul a fost generat cu succes.")

if __name__ == "__main__":
    format_dataset()